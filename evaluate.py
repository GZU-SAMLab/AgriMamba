#!/usr/bin/env python3

import argparse
import datetime
import json
import time
import os
from pathlib import Path
from contextlib import suppress
import shutil

import numpy as np
import torch
import torch.backends.cudnn as cudnn
from PIL import Image, ImageOps
import torch.nn.functional as F
from tqdm import tqdm

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from segmentation_model.config import SegmentationConfig, get_args_parser
from segmentation_model.combined_model import create_combined_model
from segmentation_model.dataset import StageDatasetWrapper
from segmentation_model.engine import evaluate_stage
from segmentation_model.utils import get_leaf_rgb_from_mask, calculate_segmentation_metrics

# å¯¼å…¥ç°æœ‰å·¥å…·
import lesion_utils as utils


def create_leaf_model(checkpoint_path: str, device: str = 'cuda'):
    """
    ä»æ£€æŸ¥ç‚¹åˆ›å»ºå¶ç‰‡åˆ†å‰²æ¨¡å‹
    """
    # å¯¼å…¥æ¨¡å‹åˆ›å»ºå‡½æ•°
    import sys
    import os.path as osp
    current_dir = osp.dirname(__file__)
    parent_dir = osp.dirname(current_dir)
    sys.path.append(parent_dir)
    
    # å¯¼å…¥æ¨¡å‹å®šä¹‰ä»¥æ³¨å†Œæ¨¡å‹
    from model.leaf_model.leaf_model import LMLS
    from timm.models import create_model
    
    # åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨å’Œè®­ç»ƒæ—¶ç›¸åŒçš„é…ç½®ï¼‰
    model, _ = create_model(
        'LMLS',
        img_size=480,  # ç»Ÿä¸€ä½¿ç”¨480å°ºå¯¸
        model_size='base'  # ä½¿ç”¨baseæ¨¡å‹ï¼Œå’Œè®­ç»ƒæ—¶ä¸€è‡´
    )
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    print(f"Loading leaf model checkpoint from {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # å¤„ç†æ£€æŸ¥ç‚¹é”®å
    if 'model' in checkpoint:
        state_dict = checkpoint['model']
    else:
        state_dict = checkpoint
    
    # ç§»é™¤å¯èƒ½çš„å‰ç¼€
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith('leaf_model.'):
            new_state_dict[k[11:]] = v
        else:
            new_state_dict[k] = v
    
    # åŠ è½½æƒé‡
    model.load_state_dict(new_state_dict)
    model = model.to(device)
    model.eval()
    
    print(f"Leaf model loaded successfully on {device}")
    return model


def extract_rgb_from_mask(original_image: Image.Image, mask: np.ndarray) -> Image.Image:
    """
    é€šè¿‡maskä»åŸå›¾ä¸­æå–RGBå›¾ï¼ˆé€šç”¨å‡½æ•°ï¼Œå¯ç”¨äºå¶å­å’Œç—…å®³ï¼‰
    
    Args:
        original_image: åŸå§‹RGBå›¾åƒ
        mask: åˆ†å‰²mask (0-1èŒƒå›´)
    
    Returns:
        rgb_image: æå–çš„RGBå›¾åƒ
    """
    # ç¡®ä¿åŸå›¾å’Œmaskå°ºå¯¸ä¸€è‡´
    if original_image.size != (mask.shape[1], mask.shape[0]):
        # å°†maskè°ƒæ•´åˆ°åŸå›¾å°ºå¯¸
        mask_image = Image.fromarray((mask * 255).astype(np.uint8), mode='L')
        mask_image = mask_image.resize(original_image.size, Image.NEAREST)
        mask = np.array(mask_image) / 255.0
    
    # è½¬æ¢åŸå›¾ä¸ºnumpyæ•°ç»„
    original_np = np.array(original_image)
    
    # ç¡®ä¿maskæ˜¯äºŒç»´çš„
    if mask.ndim == 3:
        mask = mask[:, :, 0]
    
    # äºŒå€¼åŒ–mask
    binary_mask = (mask > 0.5).astype(np.uint8)
    
    # åˆ›å»ºä¸‰é€šé“mask
    mask_3ch = np.stack([binary_mask, binary_mask, binary_mask], axis=2)
    
    # åƒç´ ç‚¹æ±‚äº¤é›†ï¼šåŸå›¾ * mask
    rgb_np = original_np * mask_3ch
    
    # è½¬æ¢å›PILå›¾åƒ
    return Image.fromarray(rgb_np.astype(np.uint8))


def create_stage1_dataset_for_evaluation(data_path: str, split: str = 'test', dataset_name: str = 'dataset4380_split'):
    """
    åˆ›å»ºç¬¬ä¸€é˜¶æ®µæ•°æ®é›†ç”¨äºè¯„ä¼°
    
    Args:
        data_path: æ•°æ®é›†è·¯å¾„
        split: æ•°æ®é›†åˆ’åˆ†
        dataset_name: æ•°æ®é›†åç§°
        
    Returns:
        dataset: æ•°æ®é›†å¯¹è±¡
    """
    # å¯¼å…¥æ•°æ®é›†ï¼ˆä»æ­£ç¡®çš„æ¨¡å—ï¼‰
    from segmentation_model.dataset import SegmentationDataset
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆåªåŠ è½½å›¾åƒï¼Œä¸åŠ è½½maskï¼‰
    dataset = SegmentationDataset(
        root=data_path,
        split=split,
        stage=1,  # åªéœ€è¦å›¾åƒ
        input_size=(480, 480),  # ç»Ÿä¸€ä½¿ç”¨480å°ºå¯¸
        dataset_name=dataset_name  # ä¼ é€’æ•°æ®é›†åç§°
    )
    
    return dataset


def evaluate_stage1_and_generate_leaf_rgb(leaf_model, data_path: str, split: str,
                                        device, config, output_dir: Path, 
                                        batch_size: int = 4, amp_autocast=suppress):
    """
    è¯„ä¼°ç¬¬ä¸€é˜¶æ®µå¹¶ç”Ÿæˆå¶å­RGBå›¾å’Œmask
    
    Args:
        leaf_model: å¶ç‰‡åˆ†å‰²æ¨¡å‹
        data_path: æ•°æ®é›†è·¯å¾„
        split: æ•°æ®é›†åˆ’åˆ†
        device: è®¾å¤‡
        config: é…ç½®
        output_dir: è¾“å‡ºç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        amp_autocast: æ··åˆç²¾åº¦ä¸Šä¸‹æ–‡
        
    Returns:
        stage1_stats: ç¬¬ä¸€é˜¶æ®µè¯„ä¼°ç»“æœ
        image_info_dict: å›¾åƒä¿¡æ¯å­—å…¸ï¼ˆç”¨äºç¬¬äºŒé˜¶æ®µï¼‰
    """
    print("=== Stage 1 Evaluation: Leaf Segmentation ===")
    
    leaf_model.eval()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    leaf_rgb_dir = output_dir / "stage1_leaf_rgb"
    leaf_mask_dir = output_dir / "leafClass"
    leaf_rgb_dir.mkdir(parents=True, exist_ok=True)
    leaf_mask_dir.mkdir(parents=True, exist_ok=True)
    
    # ä½¿ç”¨ä¸generate_stage1_results.pyç›¸åŒçš„æ•°æ®é›†åˆ›å»ºé€»è¾‘
    dataset = create_stage1_dataset_for_evaluation(data_path, split, config.data_set)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader
    data_loader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    print(f"Processing {split} set with {len(dataset)} images...")
    
    metric_logger = utils.MetricLogger(delimiter="  ")
    header = 'Stage 1 Evaluation'
    
    all_ious = []
    all_mious = []
    all_dices = []
    all_precisions = []
    all_recalls = []
    image_info_dict = {}  # å­˜å‚¨å›¾åƒä¿¡æ¯ç”¨äºç¬¬äºŒé˜¶æ®µ
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(tqdm(data_loader, desc="Generating leaf RGB images and masks")):
            # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
            images = batch['query_img'].to(device, non_blocking=True)
            img_names = batch['img_name']
            
            # ä½¿ç”¨æ··åˆç²¾åº¦æ¨ç†
            if str(device).startswith('cuda') and amp_autocast != suppress:
                with torch.amp.autocast(device_type='cuda'):
                    predictions = leaf_model(images)
            else:
                predictions = leaf_model(images)
            
            # åº”ç”¨sigmoidå¹¶è·å–é¢„æµ‹ç»“æœ
            predictions = torch.sigmoid(predictions)
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰GTï¼‰
            if 'leaf_mask' in batch:
                leaf_gt = batch['leaf_mask'].to(device, non_blocking=True).float()
                metrics = calculate_segmentation_metrics(predictions, leaf_gt)
                
                all_ious.append(metrics['iou'])
                all_mious.append(metrics['miou'])
                all_dices.append(metrics['dice'])
                all_precisions.append(metrics['precision'])
                all_recalls.append(metrics['recall'])
                
                metric_logger.update(iou=metrics['iou'])
                metric_logger.update(miou=metrics['miou'])
                metric_logger.update(dice=metrics['dice'])
                metric_logger.update(precision=metrics['precision'])
                metric_logger.update(recall=metrics['recall'])
            
            # å¤„ç†æ¯ä¸ªé¢„æµ‹ç»“æœ
            for i, img_name in enumerate(img_names):
                pred_mask = predictions[i].cpu().numpy()[0]  # å–å‡ºç¬¬ä¸€ä¸ªé€šé“
                
                # åŠ è½½å¯¹åº”çš„åŸå›¾
                original_img_path = Path(data_path) / config.data_set / split / 'img' / f"{img_name}.jpg"
                
                try:
                    # åŠ è½½åŸå›¾å¹¶å¤„ç†EXIFæ—‹è½¬ï¼Œç¡®ä¿ä¸è®­ç»ƒæ—¶ä¸€è‡´
                    original_image = Image.open(original_img_path).convert('RGB')
                    original_image = ImageOps.exif_transpose(original_image)
                    
                    # é€šè¿‡maskæå–å¶å­RGBå›¾
                    leaf_rgb_image = extract_rgb_from_mask(original_image, pred_mask)
                    
                    # ä¿å­˜å¶å­RGBå›¾
                    leaf_rgb_path = leaf_rgb_dir / f"{img_name}.jpg"
                    leaf_rgb_image.save(leaf_rgb_path, quality=95)
                    
                    # ä¿å­˜å¶ç‰‡maskï¼ˆä¿æŒä¸åŸå›¾å°ºå¯¸ä¸€è‡´ï¼‰
                    leaf_mask_path = leaf_mask_dir / f"{img_name}.png"
                    mask_image = Image.fromarray((pred_mask * 255).astype(np.uint8), mode='L')
                    mask_image = mask_image.resize(original_image.size, Image.NEAREST)
                    mask_image.save(leaf_mask_path)
                    resized_mask = np.array(mask_image, dtype=np.float32) / 255.0  # ä¿å­˜ç”¨äºåç»­å¤„ç†

                    # å­˜å‚¨å›¾åƒä¿¡æ¯ç”¨äºç¬¬äºŒé˜¶æ®µ
                    image_info_dict[img_name] = {
                        'original_image_path': str(original_img_path),
                        'leaf_rgb_path': str(leaf_rgb_path),
                        'leaf_mask_path': str(leaf_mask_path),
                        'original_image': original_image,
                        'leaf_rgb_image': leaf_rgb_image,
                        'leaf_mask': resized_mask
                    }
                    
                except Exception as e:
                    raise RuntimeError(f"Failed to process leaf segmentation for {img_name}: {e}") from e
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    metric_logger.synchronize_between_processes()
    stage1_stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}
    
    if all_ious:
        stage1_stats['mean_iou'] = sum(all_ious) / len(all_ious)
        stage1_stats['mean_miou'] = sum(all_mious) / len(all_mious)
        stage1_stats['mean_dice'] = sum(all_dices) / len(all_dices)
        stage1_stats['mean_precision'] = sum(all_precisions) / len(all_precisions)
        stage1_stats['mean_recall'] = sum(all_recalls) / len(all_recalls)
    
    print(f"Stage 1 evaluation stats: {stage1_stats}")
    print(f"Generated leaf RGB images in: {leaf_rgb_dir}")
    print(f"Generated leaf masks in: {leaf_mask_dir}")
    
    return stage1_stats, image_info_dict


def evaluate_stage2_and_generate_lesion_rgb(combined_model, image_info_dict, device, config, 
                                           output_dir: Path, batch_size: int = 4, 
                                           amp_autocast=suppress):
    """
    è¯„ä¼°ç¬¬äºŒé˜¶æ®µå¹¶ç”Ÿæˆç—…å®³RGBå›¾å’Œmask
    
    Args:
        combined_model: ç»„åˆæ¨¡å‹
        image_info_dict: å›¾åƒä¿¡æ¯å­—å…¸ï¼ˆæ¥è‡ªç¬¬ä¸€é˜¶æ®µï¼‰
        device: è®¾å¤‡
        config: é…ç½®
        output_dir: è¾“å‡ºç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        amp_autocast: æ··åˆç²¾åº¦ä¸Šä¸‹æ–‡
        
    Returns:
        stage2_stats: ç¬¬äºŒé˜¶æ®µè¯„ä¼°ç»“æœ
    """
    print("=== Stage 2 Evaluation: Lesion Segmentation ===")
    
    combined_model.eval()
    combined_model.set_stage(2)  # è®¾ç½®ä¸ºç—…å®³åˆ†å‰²æ¨¡å¼
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    lesion_rgb_dir = output_dir / "stage2_lesion_rgb"
    lesion_mask_dir = output_dir / "lesionClass"
    lesion_rgb_dir.mkdir(parents=True, exist_ok=True)
    lesion_mask_dir.mkdir(parents=True, exist_ok=True)
    
    metric_logger = utils.MetricLogger(delimiter="  ")
    header = 'Stage 2 Evaluation'
    
    all_ious = []
    all_mious = []
    all_dices = []
    all_precisions = []
    all_recalls = []
    
    # å›¾åƒå˜æ¢ï¼ˆç¬¬äºŒé˜¶æ®µä½¿ç”¨480x480ï¼‰
    import torchvision.transforms as T
    lesion_transform = T.Compose([
        T.Resize((480, 480)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # å‡†å¤‡æ‰¹æ¬¡å¤„ç†
    img_names = list(image_info_dict.keys())
    total_samples = len(img_names)
    
    with torch.no_grad():
        for batch_start in tqdm(range(0, total_samples, batch_size), desc="Generating lesion RGB images and masks"):
            batch_end = min(batch_start + batch_size, total_samples)
            batch_img_names = img_names[batch_start:batch_end]
            
            # å‡†å¤‡batchæ•°æ®
            batch_images = []
            batch_sentences = []
            batch_original_images = []
            batch_lesion_gts = []  # å­˜å‚¨ç—…å®³GT masks
            
            for img_name in batch_img_names:
                info = image_info_dict[img_name]
                
                # åŠ è½½å¶å­RGBå›¾å¹¶åº”ç”¨å˜æ¢
                leaf_rgb_image = info['leaf_rgb_image']
                leaf_rgb_tensor = lesion_transform(leaf_rgb_image)
                batch_images.append(leaf_rgb_tensor)
                
                # åŠ è½½æ–‡æœ¬æè¿°
                text_path = Path(config.data_path) / config.data_set / config.split / 'txt' / f"{img_name}.txt"
                sentence = ""
                if text_path.exists():
                    with open(text_path, 'r', encoding='utf-8') as f:
                        sentence = f.read().strip()
                    if not sentence:
                        raise ValueError(f"Text file is empty for {img_name}: {text_path}")
                else:
                    raise FileNotFoundError(f"Text file not found for {img_name}: {text_path}")
                
                batch_sentences.append(sentence)
                batch_original_images.append(info['original_image'])
                
                # åŠ è½½ç—…å®³GT maskï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                lesion_gt_path = Path(config.data_path) / config.data_set / config.split / 'lesionClass' / f"{img_name}.png"
                if lesion_gt_path.exists():
                    lesion_gt = Image.open(lesion_gt_path).convert('L')
                    lesion_gt = lesion_gt.resize((480, 480), Image.NEAREST)  # è°ƒæ•´åˆ°æ¨¡å‹è¾“å‡ºå°ºå¯¸
                    lesion_gt_np = np.array(lesion_gt) / 255.0  # å½’ä¸€åŒ–åˆ°0-1
                    lesion_gt_tensor = torch.from_numpy(lesion_gt_np).float().unsqueeze(0)  # [1, H, W]
                    batch_lesion_gts.append(lesion_gt_tensor)
                else:
                    raise FileNotFoundError(f"Lesion GT mask not found for {img_name}: {lesion_gt_path}")
            
            # è½¬æ¢ä¸ºtensorå¹¶ç§»åˆ°è®¾å¤‡
            images_tensor = torch.stack(batch_images).to(device)
            
            # ä½¿ç”¨æ··åˆç²¾åº¦æ¨ç†
            if str(device).startswith('cuda') and amp_autocast != suppress:
                with torch.amp.autocast(device_type='cuda'):
                    lesion_pred = combined_model.forward_stage2(images_tensor, batch_sentences)[0]
            else:
                lesion_pred = combined_model.forward_stage2(images_tensor, batch_sentences)[0]
            
            # åº”ç”¨sigmoidæ¿€æ´»
            lesion_pred_prob = torch.sigmoid(lesion_pred)
            
            # è®¡ç®—æ‰¹æ¬¡çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰GTï¼‰
            valid_gts = [gt for gt in batch_lesion_gts if gt is not None]
            if valid_gts and len(valid_gts) == len(batch_lesion_gts):
                # åªæœ‰å½“æ‰€æœ‰æ ·æœ¬éƒ½æœ‰GTæ—¶æ‰è®¡ç®—æŒ‡æ ‡
                try:
                    lesion_gt_batch = torch.stack(valid_gts).to(device)  # [B, 1, H, W]
                    metrics = calculate_segmentation_metrics(lesion_pred_prob, lesion_gt_batch)
                    
                    all_ious.append(metrics['iou'])
                    all_mious.append(metrics['miou'])
                    all_dices.append(metrics['dice'])
                    all_precisions.append(metrics['precision'])
                    all_recalls.append(metrics['recall'])
                    
                    metric_logger.update(iou=metrics['iou'])
                    metric_logger.update(miou=metrics['miou'])
                    metric_logger.update(dice=metrics['dice'])
                    metric_logger.update(precision=metrics['precision'])
                    metric_logger.update(recall=metrics['recall'])
                except Exception as e:
                    print(f"Error calculating metrics for batch: {e}")
            
            # å¤„ç†æ¯ä¸ªé¢„æµ‹ç»“æœ
            for i, img_name in enumerate(batch_img_names):
                pred_mask = lesion_pred_prob[i].cpu().numpy()[0]  # å–å‡ºç¬¬ä¸€ä¸ªé€šé“
                original_image = batch_original_images[i]
                
                try:
                    # é€šè¿‡maskæå–ç—…å®³RGBå›¾
                    lesion_rgb_image = extract_rgb_from_mask(original_image, pred_mask)
                    
                    # ä¿å­˜ç—…å®³RGBå›¾
                    lesion_rgb_path = lesion_rgb_dir / f"{img_name}.jpg"
                    lesion_rgb_image.save(lesion_rgb_path, quality=95)
                    
                    # ä¿å­˜ç—…å®³maskï¼ˆä¿æŒä¸åŸå›¾å°ºå¯¸ä¸€è‡´ï¼‰
                    lesion_mask_path = lesion_mask_dir / f"{img_name}.png"
                    mask_image = Image.fromarray((pred_mask * 255).astype(np.uint8), mode='L')
                    mask_image = mask_image.resize(original_image.size, Image.NEAREST)
                    mask_image.save(lesion_mask_path)

                except Exception as e:
                    raise RuntimeError(f"Failed to process lesion segmentation for {img_name}: {e}") from e
    
    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
    metric_logger.synchronize_between_processes()
    stage2_stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}
    
    if all_ious:
        stage2_stats['mean_iou'] = sum(all_ious) / len(all_ious)
        stage2_stats['mean_miou'] = sum(all_mious) / len(all_mious)
        stage2_stats['mean_dice'] = sum(all_dices) / len(all_dices)
        stage2_stats['mean_precision'] = sum(all_precisions) / len(all_precisions)
        stage2_stats['mean_recall'] = sum(all_recalls) / len(all_recalls)
        stage2_stats['processed_samples'] = len(img_names)
        stage2_stats['samples_with_gt'] = len(all_ious)
    else:
        stage2_stats = {
            'processed_samples': len(img_names),
            'samples_with_gt': 0,
            'mean_iou': 0.0,
            'mean_miou': 0.0,
            'mean_dice': 0.0,
            'mean_precision': 0.0,
            'mean_recall': 0.0,
            'note': 'No GT masks found for evaluation'
        }
    
    print(f"Stage 2 evaluation stats: {stage2_stats}")
    print(f"Generated lesion RGB images in: {lesion_rgb_dir}")
    print(f"Generated lesion masks in: {lesion_mask_dir}")
    
    return stage2_stats


def main():
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆä¸¤é˜¶æ®µè¯„ä¼°ï¼šæ¤ç‰©ç—…å®³åˆ†å‰²ç³»ç»Ÿï¼ˆç”Ÿæˆå¶å­å’Œç—…å®³çš„RGBå›¾å’Œmaskï¼‰')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--leaf-checkpoint', type=str, required=True,
                       help='å¶ç‰‡åˆ†å‰²æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¿…éœ€ï¼‰')
    parser.add_argument('--lesion-checkpoint', type=str, required=True,
                       help='ç—…å®³åˆ†å‰²æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¿…éœ€ï¼‰')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--data-path', default='./dataset', help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--data-set', default='dataset4380_split', type=str, help='æ•°æ®é›†åç§°')
    parser.add_argument('--output-dir', default='./output/evaluation_enhanced', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--batch-size', type=int, default=4, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--device', default='cuda', help='è®¾å¤‡')
    parser.add_argument('--seed', type=int, default=0, help='éšæœºç§å­')
    parser.add_argument('--split', default='test', help='è¯„ä¼°æ•°æ®é›†åˆ’åˆ† (train/val/test)')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--save-intermediate', action='store_true', default=True,
                       help='ä¿å­˜ä¸­é—´ç»“æœï¼ˆå¶å­å’Œç—…å®³çš„RGBå›¾å’Œmaskï¼‰')
    parser.add_argument('--cleanup-intermediate', action='store_true', default=False,
                       help='è¯„æµ‹ç»“æŸååˆ é™¤ä¸­é—´æ–‡ä»¶ï¼ˆå¶å­å’Œç—…å®³çš„RGBå›¾å’Œmaskå›¾ï¼‰')
    parser.add_argument('--if-amp', action='store_true', default=True,
                       help='å¯ç”¨æ··åˆç²¾åº¦æ¨ç†')
    parser.add_argument('--no-amp', action='store_false', dest='if_amp',
                       help='ç¦ç”¨æ··åˆç²¾åº¦æ¨ç†')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å¿…éœ€çš„æ£€æŸ¥ç‚¹æ–‡ä»¶
    if not os.path.exists(args.leaf_checkpoint):
        print(f" é”™è¯¯ï¼šå¶ç‰‡æ¨¡å‹æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {args.leaf_checkpoint}")
        return
        
    if not os.path.exists(args.lesion_checkpoint):
        print(f" é”™è¯¯ï¼šç—…å®³æ¨¡å‹æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {args.lesion_checkpoint}")
        return
    
    # åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ
    utils.init_distributed_mode(args)
    print(f"Arguments: {args}")
    
    # è®¾å¤‡æ£€æµ‹å’Œè‡ªåŠ¨å›é€€
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("Warning: CUDA requested but not available, falling back to CPU")
        args.device = 'cpu'
        device = torch.device('cpu')
    else:
        device = torch.device(args.device)
    
    print(f"Using device: {device}")
    
    # åˆ›å»ºé…ç½®
    full_args = argparse.Namespace(
        data_path=args.data_path,
        data_set=args.data_set,
        input_size=480,  # ç¬¬äºŒé˜¶æ®µç”¨480
        batch_size=args.batch_size,
        epochs=50,
        lr=5e-5,
        leaf_lr=5e-5,
        leaf_epochs=25,
        leaf_weight_decay=1e-4,
        lr_backbone=2.5e-5,
        lesion_lr=3e-5,
        lesion_epochs=25,
        lesion_weight_decay=1e-4,
        lr_decoder=3e-5,
        lr_vssm=2.5e-5,
        stage=0,
        freeze_leaf=True,
        stage1_results='',
        generate_stage1_results=False,
        pretrain_path='./pretrain',
        output_dir=args.output_dir,
        resume='',
        eval=True,
        device=args.device,
        seed=args.seed,
        num_workers=8,
        pin_mem=True,
        if_amp=args.if_amp,
        distributed=False,
        world_size=1,
        dist_url='env://',
        local_rank=0,
        opt='adamw',
        sched='cosine',
        warmup_epochs=0,
        min_lr=1e-6,
        warmup_lr=1e-6,
        decay_epochs=30,
        cooldown_epochs=10,
        patience_epochs=10,
        decay_rate=0.1,
        drop=0.0,
        drop_path=0.1,
        split=args.split  # æ·»åŠ splitåˆ°é…ç½®ä¸­
    )
    
    config = SegmentationConfig.from_args(full_args)
    config.device = args.device
    config.split = args.split  # ç¡®ä¿splitåœ¨configä¸­å¯ç”¨
    
    print(f"Configuration: {config.to_dict()}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜é…ç½®
    if utils.is_main_process():
        with (output_dir / "config.json").open("w") as f:
            json.dump(config.to_dict(), f, indent=4)
    
    # è®¾ç½®éšæœºç§å­
    seed = args.seed + utils.get_rank()
    torch.manual_seed(seed)
    np.random.seed(seed)
    cudnn.benchmark = True
    
    # AMPè®¾ç½®
    amp_autocast = suppress
    if config.training_config['if_amp'] and torch.cuda.is_available():
        amp_autocast = torch.cuda.amp.autocast
        print("Using AMP for inference")
    else:
        print("AMP disabled (CUDA not available or disabled)")
    
    # åˆ›å»ºæ¨¡å‹
    print("=== Starting Enhanced Two-Stage Evaluation ===")
    
    # ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºç›´æ¥çš„å¶ç‰‡æ¨¡å‹
    print(f"Creating direct leaf model from checkpoint: {args.leaf_checkpoint}")
    leaf_model = create_leaf_model(args.leaf_checkpoint, device)
    
    # ç¬¬äºŒé˜¶æ®µï¼šåˆ›å»ºç—…å®³æ¨¡å‹
    print("Creating combined model for lesion segmentation...")
    combined_model = create_combined_model(config, stage=0, device=device)
    print(f"Loading lesion model checkpoint from {args.lesion_checkpoint}")
    combined_model.load_lesion_checkpoint(args.lesion_checkpoint)
    
    print(" Both models loaded successfully")
    
    # é˜¶æ®µ1è¯„ä¼°å’Œå¶å­RGBå›¾ç”Ÿæˆ
    print(f"\n=== Step 1: Evaluating Stage 1 and Generating Leaf RGB Images and Masks (Split: {args.split}) ===")
    start_time = time.time()
    
    stage1_stats, image_info_dict = evaluate_stage1_and_generate_leaf_rgb(
        leaf_model=leaf_model,
        data_path=args.data_path,
        split=args.split,
        device=device,
        config=config,
        output_dir=output_dir,
        batch_size=args.batch_size,
        amp_autocast=amp_autocast
    )
    
    stage1_time = time.time() - start_time
    print(f" Stage 1 evaluation completed in {stage1_time:.2f} seconds")
    
    # é˜¶æ®µ2è¯„ä¼°å’Œç—…å®³RGBå›¾ç”Ÿæˆ
    print("\n=== Step 2: Evaluating Stage 2 and Generating Lesion RGB Images and Masks ===")
    start_time = time.time()
    
    stage2_stats = evaluate_stage2_and_generate_lesion_rgb(
        combined_model=combined_model,
        image_info_dict=image_info_dict,
        device=device,
        config=config,
        output_dir=output_dir,
        batch_size=args.batch_size,
        amp_autocast=amp_autocast
    )
    
    stage2_time = time.time() - start_time
    print(f" Stage 2 evaluation completed in {stage2_time:.2f} seconds")
    
    # æ±‡æ€»ç»“æœ
    total_time = stage1_time + stage2_time
    
    print(f"\n Enhanced two-stage evaluation completed in {total_time:.2f} seconds")
    print(f" Evaluation Results:")
    print(f"   - Stage 1 (Leaf) IoU: {stage1_stats.get('mean_iou', 0):.4f}")
    print(f"   - Stage 1 (Leaf) mIoU: {stage1_stats.get('mean_miou', 0):.4f}")
    print(f"   - Stage 1 (Leaf) Dice: {stage1_stats.get('mean_dice', 0):.4f}")
    print(f"   - Stage 1 (Leaf) Precision: {stage1_stats.get('mean_precision', 0):.4f}")
    print(f"   - Stage 1 (Leaf) Recall: {stage1_stats.get('mean_recall', 0):.4f}")
    print(f"   - Stage 2 (Lesion) IoU: {stage2_stats.get('mean_iou', 0):.4f}")
    print(f"   - Stage 2 (Lesion) mIoU: {stage2_stats.get('mean_miou', 0):.4f}")
    print(f"   - Stage 2 (Lesion) Dice: {stage2_stats.get('mean_dice', 0):.4f}")
    print(f"   - Stage 2 (Lesion) Precision: {stage2_stats.get('mean_precision', 0):.4f}")
    print(f"   - Stage 2 (Lesion) Recall: {stage2_stats.get('mean_recall', 0):.4f}")
    print(f"   - Stage 2 processed samples: {stage2_stats.get('processed_samples', 0)}")
    print(f"   - Stage 2 samples with GT: {stage2_stats.get('samples_with_gt', 0)}")
    print(f"   - Total Samples: {len(image_info_dict)}")
    
    # ä¿å­˜ç»“æœ
    if utils.is_main_process():
        # æ±‡æ€»è¯„ä¼°ç»“æœ
        final_results = {
            'stage1_results': stage1_stats,
            'stage2_results': stage2_stats,
            'summary': {
                'leaf_iou': stage1_stats.get('mean_iou', 0),
                'leaf_miou': stage1_stats.get('mean_miou', 0),
                'leaf_dice': stage1_stats.get('mean_dice', 0),
                'leaf_precision': stage1_stats.get('mean_precision', 0),
                'leaf_recall': stage1_stats.get('mean_recall', 0),
                'lesion_iou': stage2_stats.get('mean_iou', 0),
                'lesion_miou': stage2_stats.get('mean_miou', 0),
                'lesion_dice': stage2_stats.get('mean_dice', 0),
                'lesion_precision': stage2_stats.get('mean_precision', 0),
                'lesion_recall': stage2_stats.get('mean_recall', 0),
                'lesion_processed_samples': stage2_stats.get('processed_samples', 0),
                'lesion_samples_with_gt': stage2_stats.get('samples_with_gt', 0),
                'total_samples': len(image_info_dict),
                'stage1_time': stage1_time,
                'stage2_time': stage2_time,
                'total_time': total_time
            },
            'evaluation_metadata': {
                'leaf_checkpoint': args.leaf_checkpoint,
                'lesion_checkpoint': args.lesion_checkpoint,
                'evaluation_type': 'enhanced_two_stage',
                'batch_size': args.batch_size,
                'device': args.device,
                'split': args.split,
                'img_size_stage1': 480,
                'img_size_stage2': 480,
                'timestamp': datetime.datetime.now().isoformat()
            }
        }
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        result_filename = "evaluation_results_enhanced.json"
        with (output_dir / result_filename).open("w") as f:
            json.dump(final_results, f, indent=4, default=str)
        
        print(f"\n Evaluation results saved to: {output_dir / result_filename}")
        
        # ä¿å­˜ç®€è¦æŠ¥å‘Š
        summary_report = {
            'method': 'enhanced_two_stage_evaluation',
            'leaf_iou': stage1_stats.get('mean_iou', 0),
            'leaf_miou': stage1_stats.get('mean_miou', 0),
            'leaf_dice': stage1_stats.get('mean_dice', 0),
            'leaf_precision': stage1_stats.get('mean_precision', 0),
            'leaf_recall': stage1_stats.get('mean_recall', 0),
            'lesion_iou': stage2_stats.get('mean_iou', 0),
            'lesion_miou': stage2_stats.get('mean_miou', 0),
            'lesion_dice': stage2_stats.get('mean_dice', 0),
            'lesion_precision': stage2_stats.get('mean_precision', 0),
            'lesion_recall': stage2_stats.get('mean_recall', 0),
            'lesion_samples_processed': stage2_stats.get('processed_samples', 0),
            'lesion_samples_with_gt': stage2_stats.get('samples_with_gt', 0),
            'total_time': total_time,
            'output_directories': {
                'leaf_rgb': str(output_dir / 'stage1_leaf_rgb'),
                'leaf_masks': str(output_dir / 'leafClass'),
                'lesion_rgb': str(output_dir / 'stage2_lesion_rgb'),
                'lesion_masks': str(output_dir / 'lesionClass')
            }
        }
        
        with (output_dir / "evaluation_summary_enhanced.json").open("w") as f:
            json.dump(summary_report, f, indent=4)
        
        print(f" Summary report saved to: {output_dir / 'evaluation_summary_enhanced.json'}")
        
        if args.save_intermediate:
            print(f" Leaf RGB images saved in: {output_dir / 'stage1_leaf_rgb'}")
            print(f" Leaf masks saved in: {output_dir / 'leafClass'}")
            print(f" Lesion RGB images saved in: {output_dir / 'stage2_lesion_rgb'}")
            print(f" Lesion masks saved in: {output_dir / 'lesionClass'}")
    
    # æ¸…ç†ä¸­é—´æ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if args.cleanup_intermediate and args.save_intermediate:
        print(f"\nğŸ§¹ Cleaning up intermediate files...")
        try:
            # æ¸…ç†å¶å­ç›¸å…³æ–‡ä»¶
            leaf_rgb_dir = output_dir / "stage1_leaf_rgb"
            leaf_mask_dir = output_dir / "leafClass"
            
            if leaf_rgb_dir.exists():
                shutil.rmtree(leaf_rgb_dir)
                print(f" Deleted leaf RGB images directory: {leaf_rgb_dir}")
            
            if leaf_mask_dir.exists():
                shutil.rmtree(leaf_mask_dir)
                print(f" Deleted leaf masks directory: {leaf_mask_dir}")
            
            # æ¸…ç†ç—…å®³ç›¸å…³æ–‡ä»¶
            lesion_rgb_dir = output_dir / "stage2_lesion_rgb"
            lesion_mask_dir = output_dir / "lesionClass"
            
            if lesion_rgb_dir.exists():
                shutil.rmtree(lesion_rgb_dir)
                print(f" Deleted lesion RGB images directory: {lesion_rgb_dir}")
            
            if lesion_mask_dir.exists():
                shutil.rmtree(lesion_mask_dir)
                print(f" Deleted lesion masks directory: {lesion_mask_dir}")
                
        except Exception as e:
            print(f" Warning: Failed to clean up intermediate files: {e}")
    elif args.cleanup_intermediate and not args.save_intermediate:
        print(f" Note: --cleanup-intermediate has no effect when --save-intermediate is disabled")
    
    print(f"\n Enhanced two-stage evaluation completed successfully!")
    
    return final_results


if __name__ == '__main__':
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    main() 
